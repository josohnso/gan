{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of make_LANDSCAPE_pretrain_Generator_v0.3.5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f4740d92ebe4a6b82a0cd1cbc9a0529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3efcd9860f654546b8d55dbce4f6702d",
              "IPY_MODEL_734cffdc06af48df9ea2328f914e85c9"
            ],
            "layout": "IPY_MODEL_2537dac877d24de08f17806d23a42057"
          }
        },
        "3efcd9860f654546b8d55dbce4f6702d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e07267b9af4deebeaba2007ceb187c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f66f668e88048d496a5a47e40e776b9",
            "value": 1
          }
        },
        "734cffdc06af48df9ea2328f914e85c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2450beb9704d98b4ffcfec325036d9",
            "placeholder": "​",
            "style": "IPY_MODEL_1273d173a3e94473b619cbdc54f70cef",
            "value": " 16/? [00:16&lt;00:00,  1.01it/s]"
          }
        },
        "2537dac877d24de08f17806d23a42057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e07267b9af4deebeaba2007ceb187c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f66f668e88048d496a5a47e40e776b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "dc2450beb9704d98b4ffcfec325036d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1273d173a3e94473b619cbdc54f70cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2LONgCSHkKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target\n",
        "target = 'landscape'\n",
        "target_JP = '風景'\n",
        "\n",
        "# hyper params\n",
        "EPOCHS = (4, 8, 16, 32, 48, 48, 64)\n",
        "BATCH_SIZES = (96, 96, 96, 64, 64, 48, 48)\n",
        "initial_scale = 1.\n",
        "GPU = 0\n",
        "\n",
        "# extension params\n",
        "log_interval = 5000\n",
        "display_interval = None\n",
        "tweet_interval = 5000\n",
        "snapshot_interval = 5000\n",
        "\n",
        "# model params\n",
        "sa_gamma = 1.\n",
        "START = 3\n",
        "IMG_SIZE = 256\n",
        "CH_SIZE = 8\n",
        "LATENT_SIZE = 64\n",
        "HIDDEN_SIZE = 4\n",
        "\n",
        "# learning controller\n",
        "learning_rate = 2e-4\n",
        "grad_clip = None\n",
        "gen_weight_decay = 0\n",
        "dis_weight_decay = 0\n",
        "sa_endpoint = 10000\n",
        "sg_endpoint = 1\n",
        "\n",
        "# file names\n",
        "load_gen = (32, 11)\n",
        "load_dis = (32, 11)\n",
        "\n",
        "OUT = './result/'\n",
        "dataroot = './picture/train_pic/flickr/landscape'\n",
        "\n",
        "gen_name = '{}_gen'.format(target)\n",
        "dis_name = '{}_dis'.format(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "taibgWsxewAT",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import uuid\n",
        "import pickle\n",
        "import tweepy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm, clip_grad_norm_\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import twitter_api_key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sMBmUGbfmmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian(size):\n",
        "    return torch.normal(torch.zeros(size), torch.ones(size))\n",
        "\n",
        "def zeropad(x, ch):\n",
        "    return F.pad(x, (0, 0, 0, 0, 0, ch-x.size(1), 0, 0))\n",
        "\n",
        "def gap(x):\n",
        "    return F.avg_pool2d(x, x.size()[-2:])\n",
        "\n",
        "def instance_var(x):\n",
        "    _shape = x.size()\n",
        "    _x = x.view(_shape[0], _shape[1], -1)\n",
        "    _x = torch.var(_x, dim=2)\n",
        "    _x = _x.view(*_x.size(), 1, 1)\n",
        "    _x = _x.expand(*_shape)\n",
        "    return _x\n",
        "\n",
        "def pixel_norm(x):\n",
        "    return x * torch.rsqrt((x**2).mean(1, keepdim=True) + 1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "255V-NaDeLIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=1, stride=1, padding=0):\n",
        "        super(SNConv, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Conv2d(in_ch, out_ch, kernel, stride, padding))\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWziEjG0ZooZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNRes(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=3, stride=1, padding=1):\n",
        "        super(SNRes, self).__init__()\n",
        "        self.main = SNConv(in_ch, out_ch, kernel, stride, padding)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x + self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdvHzeEdlxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNDense(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(SNDense, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Linear(in_ch, out_ch))\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz5PrYJQex1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNSelfAttentionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, gamma=1.):\n",
        "        super(SNSelfAttentionBlock, self).__init__()\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.cf = SNConv(in_ch, out_ch//8)\n",
        "        self.cg = SNConv(in_ch, out_ch//8)\n",
        "        self.ch = SNConv(in_ch, out_ch)\n",
        "        self.softmax = nn.Softmax(2)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        f = self.cf(x)\n",
        "        g = self.cg(x)\n",
        "        h = self.ch(x)\n",
        "        f = f.view(f.size(0), f.size(1), -1)\n",
        "        g = g.view(g.size(0), g.size(1), -1)\n",
        "        h = h.view(h.size(0), h.size(1), -1)\n",
        "        \n",
        "        attention_map = torch.bmm(torch.transpose(f, 1, 2), g)\n",
        "        attention_map = self.softmax(attention_map)\n",
        "        feature_map = torch.bmm(h, torch.transpose(attention_map, 1, 2))\n",
        "        feature_map = feature_map.view(*x.size())\n",
        "\n",
        "        return x + feature_map*self.gamma\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        self.gamma = gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yv0ZlRisUb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MinibatchDiscrimination(nn.Module):\n",
        "    def __init__(self, in_ch, kernel, kernel_dims, device):\n",
        "        super(MinibatchDiscrimination, self).__init__()\n",
        "        self.device = device\n",
        "        self.kernel = kernel\n",
        "        self.dim = kernel_dims\n",
        "        self.t = nn.Linear(in_ch, self.kernel*self.dim, bias=False)\n",
        "        for param in self.t.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batchsize = x.size(0)\n",
        "        m = self.t(x).view(batchsize, self.kernel, self.dim, 1)\n",
        "        m_T = torch.transpose(m, 0, 3)\n",
        "        m, m_T = torch.broadcast_tensors(m, m_T)\n",
        "        norm = torch.sum(F.l1_loss(m, m_T, reduction='none'), dim=2)\n",
        "\n",
        "        eraser = torch.eye(batchsize, device=self.device).view(batchsize, 1, batchsize).expand(norm.size())\n",
        "        c_b = torch.exp(-(norm + 1e6 * eraser))\n",
        "        o_b = torch.sum(c_b, dim=2)\n",
        "        h = torch.cat((x, o_b), dim=1)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By7GhkDdFG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "\n",
        "        self.layer_11 = SNConv(in_ch, mid_ch)\n",
        "        self.layer_33_1 = nn.Sequential(\n",
        "            SNConv(in_ch, mid_ch),\n",
        "            SNConv(mid_ch, mid_ch, 3, 1, 1)\n",
        "        )\n",
        "        self.layer_33_2 = nn.Sequential(\n",
        "            SNConv(in_ch, mid_ch),\n",
        "            SNConv(mid_ch, mid_ch, 3, 1, 1),\n",
        "            SNRes(mid_ch, mid_ch)\n",
        "        )\n",
        "\n",
        "        self.c = SNConv(mid_ch*3, out_ch)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        h_11 = self.layer_11(x)\n",
        "        h_33_1 = self.layer_33_1(x)\n",
        "        h_33_2 = self.layer_33_2(x)\n",
        "        \n",
        "        h = torch.cat((h_11, h_33_1, h_33_2), dim=1)\n",
        "        h = self.c(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAucx40aUr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(InceptionResBlock, self).__init__()\n",
        "        self.ch = out_ch\n",
        "        self.inception = InceptionBlock(in_ch, self.ch//4, self.ch)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        _h = self.inception(x)\n",
        "        h = zeropad(x, self.ch)\n",
        "        return h + _h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-drx6j6OvQpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, sa_gamma=None):\n",
        "        super(DiscriminatorBlock, self).__init__()\n",
        "        self.main = InceptionResBlock(in_ch, in_ch*2)\n",
        "        self.sa = SNSelfAttentionBlock(in_ch*2, in_ch*2, gamma=sa_gamma) if sa_gamma else None\n",
        "\n",
        "        self.c = SNConv(in_ch*2, out_ch)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        h = self.main(x)\n",
        "\n",
        "        if self.sa:\n",
        "            h = self.sa(h)\n",
        "\n",
        "        h = self.c(h)\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        if self.sa:\n",
        "            self.sa.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzW6AWqpGp8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, out_ch=2, device=None, sa_gamma=1.):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.in_256 = spectral_norm(nn.Conv2d(3, 32, 1, 1, 0))\n",
        "        self.layer_256 = nn.Sequential(\n",
        "            DiscriminatorBlock(32, 64),\n",
        "            SNConv(64, 64, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_128 = spectral_norm(nn.Conv2d(3, 64, 1, 1, 0))\n",
        "        self.layer_128 = nn.Sequential(\n",
        "            DiscriminatorBlock(64, 128),\n",
        "            SNConv(128, 128, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_64 = spectral_norm(nn.Conv2d(3, 128, 1, 1, 0))\n",
        "        self.layer_64 = nn.Sequential(\n",
        "            DiscriminatorBlock(128, 256),\n",
        "            SNConv(256, 256, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_32 = spectral_norm(nn.Conv2d(3, 256, 1, 1, 0))\n",
        "        self.layer_32 = nn.Sequential(\n",
        "            DiscriminatorBlock(256, 512),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_16 = spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_16 = nn.Sequential(\n",
        "            DiscriminatorBlock(512, 512, sa_gamma=sa_gamma),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_8 = spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_8 = nn.Sequential(\n",
        "            DiscriminatorBlock(512, 512, sa_gamma=sa_gamma),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_4 =  spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_4 = nn.Sequential(\n",
        "            DiscriminatorBlock(512, 512, sa_gamma=sa_gamma),\n",
        "            nn.AvgPool2d(4),\n",
        "            nn.Flatten(),\n",
        "            MinibatchDiscrimination(512, 64, 16, device),\n",
        "            SNDense(512+64, out_ch)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, img_size, delta=None):\n",
        "\n",
        "        if img_size >= 256:\n",
        "            h = self.in_256(x)\n",
        "            h = self.layer_256(h)\n",
        "        else:\n",
        "            h = 0\n",
        "        \n",
        "        if img_size >= 128:\n",
        "            if img_size == 128:\n",
        "                _x = F.avg_pool2d(x, img_size//128)\n",
        "                h = h + self.in_128(_x)\n",
        "            elif delta and img_size == 256:\n",
        "                _x = F.avg_pool2d(x, img_size//128)\n",
        "                h = torch.lerp(self.in_128(_x), h, delta)\n",
        "            h = self.layer_128(h)\n",
        "        \n",
        "        if img_size >= 64:\n",
        "            if img_size == 64:\n",
        "                _x = F.avg_pool2d(x, img_size//64)\n",
        "                h = h + self.in_64(_x)\n",
        "            elif delta and img_size == 128:\n",
        "                _x = F.avg_pool2d(x, img_size//64)\n",
        "                h = torch.lerp(self.in_64(_x), h, delta)\n",
        "            h = self.layer_64(h)\n",
        "        \n",
        "        if img_size >= 32:\n",
        "            if img_size == 32:\n",
        "                _x = F.avg_pool2d(x, img_size//32)\n",
        "                h = h + self.in_32(_x)\n",
        "            elif delta and img_size == 64:\n",
        "                _x = F.avg_pool2d(x, img_size//32)\n",
        "                h = torch.lerp(self.in_32(_x), h, delta)\n",
        "            h = self.layer_32(h)\n",
        "        \n",
        "        if img_size >= 16:\n",
        "            if img_size == 16:\n",
        "                _x = F.avg_pool2d(x, img_size//16)\n",
        "                h = h + self.in_16(_x)\n",
        "            elif delta and img_size == 32:\n",
        "                _x = F.avg_pool2d(x, img_size//16)\n",
        "                h = torch.lerp(self.in_16(_x), h, delta)\n",
        "            h = self.layer_16(h)\n",
        "\n",
        "        if img_size >= 8:\n",
        "            if img_size == 8:\n",
        "                _x = F.avg_pool2d(x, img_size//8)\n",
        "                h = h + self.in_8(_x)\n",
        "            elif delta and img_size == 16:\n",
        "                _x = F.avg_pool2d(x, img_size//8)\n",
        "                h = torch.lerp(self.in_8(_x), h, delta)\n",
        "            h = self.layer_8(h)\n",
        "\n",
        "        if img_size == 4:\n",
        "            _x = F.avg_pool2d(x, img_size//4)\n",
        "            h = h + self.in_4(_x)\n",
        "        elif delta and img_size == 8:\n",
        "            _x = F.avg_pool2d(x, img_size//4)\n",
        "            h = torch.lerp(self.in_4(_x), h, delta)\n",
        "        h = self.layer_4(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma, img_size):\n",
        "        if img_size == 8:\n",
        "            self.layer_4[0].set_gamma(gamma)\n",
        "        if img_size == 16:\n",
        "            self.layer_8[0].set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT6qSzQ-hq_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LatentGenerator(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, device=None):\n",
        "        super(LatentGenerator, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.mu = spectral_norm(nn.Linear(in_ch, out_ch))\n",
        "        self.var = spectral_norm(nn.Linear(in_ch, out_ch))\n",
        "\n",
        "    def forward(self, w):\n",
        "        mu = self.mu(w)\n",
        "        var = self.var(w)\n",
        "        h = mu + var * gaussian(var.size()).to(self.device)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scShQFu8ttNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoiseInjection(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, device=None):\n",
        "        super(NoiseInjection, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.var = SNDense(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        var = self.var(w)\n",
        "        var = var.view(*var.size(), 1, 1).expand(*x.size())\n",
        "        noise = gaussian(x.size()).to(self.device)\n",
        "        return x + noise * var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KdRypCUwmjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaIN(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch, device=None):\n",
        "        super(AdaIN, self).__init__()\n",
        "\n",
        "        self.noise_injection = NoiseInjection(in_ch, out_ch, device)\n",
        "        self.lg = LatentGenerator(in_ch, mid_ch, device)\n",
        "        self.average_convert = SNDense(mid_ch, out_ch)\n",
        "        self.bias_convert = SNDense(mid_ch, out_ch)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        h = F.instance_norm(x)\n",
        "        h = self.noise_injection(h, w)\n",
        "        \n",
        "        _w = self.lg(w)\n",
        "        a = self.average_convert(_w)\n",
        "        a = a.view(*a.size(), 1, 1).expand(*h.size())\n",
        "        b = self.bias_convert(_w)\n",
        "        b = b.view(*b.size(), 1, 1).expand(*h.size())\n",
        "        h = h * a + b\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zTVuBAFqAjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DepthwiseCondConv(nn.Module):\n",
        "    def __init__(self, in_ch, n_kernels, kernel=3, stride=1, padding=1, device=None, k=1):\n",
        "        super(DepthwiseCondConv, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.kernel = kernel\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.ch = in_ch\n",
        "        self.kernels_size = (n_kernels, kernel, kernel)\n",
        "\n",
        "        self.weight = nn.Parameter(torch.empty(k, n_kernels, kernel, kernel))\n",
        "        nn.init.xavier_normal_(self.weight)\n",
        "    \n",
        "    def forward(self, x, sigma, bias=None):\n",
        "        b_size = x.size(0)\n",
        "\n",
        "        h = F.leaky_relu(x, negative_slope=0.2)\n",
        "        \n",
        "        kernels = self.weight.view(self.weight.size(0), -1, 1)\n",
        "        kernels = kernels.transpose(0, 1)\n",
        "        kernels = kernels.expand(-1, -1, self.ch)\n",
        "\n",
        "        i = torch.eye(self.ch).to(self.device)\n",
        "        i = i.view(1, self.ch, self.ch)\n",
        "        i = i.expand(kernels.size(0), -1, -1)\n",
        "        \n",
        "        kernels = i*kernels\n",
        "        kernels = kernels.view(*self.kernels_size, self.ch, -1)\n",
        "        kernels = kernels.transpose(1, 3).transpose(2, 4)\n",
        "        kernels = kernels.expand(b_size, -1, -1, -1, -1, -1)\n",
        "\n",
        "        _s = sigma.view(*kernels.size()[:3], 1, 1, 1)\n",
        "        _s = _s.expand(-1, -1, -1, self.ch, -1, -1)\n",
        "        _s = torch.sum(kernels*_s, dim=1)\n",
        "        _s = _s.reshape(b_size, self.ch, -1)\n",
        "\n",
        "        h = F.unfold(h, self.kernel, padding=self.padding, stride=self.stride)\n",
        "        h = torch.bmm(_s, h)\n",
        "        h = h.view(b_size, self.ch, *x.size()[2:])\n",
        "\n",
        "        if bias is not None:\n",
        "            _b = bias.view(-1, self.ch, 1, 1)\n",
        "            h = h + _b\n",
        "        \n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yiNF-rUsXo9i",
        "colab": {}
      },
      "source": [
        "class SynthBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, latent_ch, mid_ch, kernels, device=None):\n",
        "        super(SynthBlock, self).__init__()\n",
        "\n",
        "        self.lg = LatentGenerator(latent_ch, mid_ch, device)\n",
        "        self.sigma = nn.Sequential(\n",
        "            SNDense(mid_ch, in_ch*kernels),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.bias = SNDense(mid_ch, in_ch)\n",
        "\n",
        "        self.dcc = spectral_norm(DepthwiseCondConv(in_ch, kernels, device=device))\n",
        "        self.c = SNConv(in_ch, out_ch)\n",
        "        self.adain = AdaIN(latent_ch, mid_ch, out_ch, device)\n",
        "            \n",
        "    def forward(self, x, w):\n",
        "        _w = self.lg(w)\n",
        "        sigma = self.sigma(_w)\n",
        "        bias = self.bias(_w)\n",
        "\n",
        "        h = self.dcc(x, sigma, bias)\n",
        "        h = self.c(h)\n",
        "        h = self.adain(h, w)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2Rk_jFc7Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, latent_ch, mid_ch, kernels, device=None, sa_gamma=None):\n",
        "        super(GeneratorBlock, self).__init__()\n",
        "        \n",
        "        self.synth_0 = SynthBlock(in_ch, out_ch, latent_ch, mid_ch, kernels, device)\n",
        "        self.synth_1 = SynthBlock(out_ch, out_ch, latent_ch, mid_ch, kernels, device)\n",
        "        self.sa = SNSelfAttentionBlock(out_ch, out_ch, gamma=sa_gamma) if sa_gamma else None\n",
        "            \n",
        "    def forward(self, x, w):\n",
        "        h = self.synth_0(x, w)\n",
        "        h = h + self.synth_1(h, w)\n",
        "\n",
        "        if self.sa:\n",
        "            h = self.sa(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        if self.sa:\n",
        "            self.sa.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj6mVO7FnuuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OutputGenerator(nn.Module):\n",
        "    def __init__(self, ch_size):\n",
        "        super(OutputGenerator, self).__init__()\n",
        "        self.ch_size = ch_size\n",
        "\n",
        "        self.c_out = SNConv(ch_size, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.ch_size != x.size(1):\n",
        "            h = x.view(x.size(0), self.ch_size//2, -1, *x.size()[2:])\n",
        "            h = torch.cat((h[:,:,0,:,:], h[:,:,-1,:,:]), dim=1)\n",
        "        else:\n",
        "            h = x\n",
        "\n",
        "        h = self.c_out(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKEhOWEuFqEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, ch_size, latent_size, hidden_size, device=None, sa_gamma=1., kernels=6):\n",
        "        super(Generator, self).__init__()\n",
        "        self.device = device\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        self.btm = nn.Parameter(torch.empty(1, ch_size*32, 4, 4))\n",
        "        nn.init.normal_(self.btm)\n",
        "        \n",
        "        self.res6 = GeneratorBlock(ch_size*32, ch_size*64, latent_size, hidden_size*64, kernels, device, sa_gamma)\n",
        "        self.out6 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.res5 = GeneratorBlock(ch_size*16, ch_size*32, latent_size, hidden_size*32, kernels, device, sa_gamma)\n",
        "        self.out5 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.res4 = GeneratorBlock(ch_size*8, ch_size*16, latent_size, hidden_size*16, kernels, device)\n",
        "        self.out4 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.res3 = GeneratorBlock(ch_size*4, ch_size*8, latent_size, hidden_size*8, kernels, device)\n",
        "        self.out3 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.res2 = GeneratorBlock(ch_size*2, ch_size*4, latent_size, hidden_size*4, kernels, device)\n",
        "        self.out2 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.res1 = GeneratorBlock(ch_size, ch_size*2, latent_size, hidden_size*2, kernels, device)\n",
        "        self.out1 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.res0 = GeneratorBlock(ch_size//2, ch_size, latent_size, hidden_size, kernels, device)\n",
        "        self.out0 = OutputGenerator(ch_size)\n",
        "\n",
        "        self.upbi = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.upps = nn.PixelShuffle(2)\n",
        "    \n",
        "    def forward(self, batch, img_size, delta=None):\n",
        "        w = pixel_norm(gaussian((batch, self.latent_size)).to(self.device))\n",
        "        h = self.btm.expand(batch, -1, -1, -1)\n",
        "        h = self.res6(h, w)\n",
        "        out = self.out6(h)\n",
        "        \n",
        "        if img_size >= 8:\n",
        "            h = self.upps(h)\n",
        "            h = self.res5(h, w)\n",
        "            _out = self.out5(h)\n",
        "            if delta and img_size == 8:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "        \n",
        "        if img_size >= 16:\n",
        "            h = self.upps(h)\n",
        "            h = self.res4(h, w)\n",
        "            _out = self.out4(h)\n",
        "            if delta and img_size == 16:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "\n",
        "        if img_size >= 32:\n",
        "            h = self.upps(h)\n",
        "            h = self.res3(h, w)\n",
        "            _out = self.out3(h)\n",
        "            if delta and img_size == 32:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "\n",
        "        if img_size >= 64:\n",
        "            h = self.upps(h)\n",
        "            h = self.res2(h, w)\n",
        "            _out = self.out2(h)\n",
        "            if delta and img_size == 64:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "        \n",
        "        if img_size >= 128:\n",
        "            h = self.upps(h)\n",
        "            h = self.res1(h, w)\n",
        "            _out = self.out1(h)\n",
        "            if delta and img_size == 128:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "        \n",
        "        if img_size >= 256:\n",
        "            h = self.upps(h)\n",
        "            h = self.res0(h, w)\n",
        "            _out = self.out0(h)\n",
        "            if delta and img_size == 256:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "\n",
        "        return torch.tanh(out)\n",
        "\n",
        "    def set_gamma(self, gamma, img_size):\n",
        "        if img_size == 8:\n",
        "            self.res6.set_gamma(gamma)\n",
        "        if img_size == 16:\n",
        "            self.res5.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RvlFlUWVgCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:{}\".format(GPU))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjzxAjvT6VPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    if type(m) in (nn.Linear, nn.Conv2d):\n",
        "        nn.init.xavier_normal_(m.weight, gain=initial_scale)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "    elif type(m) in (nn.BatchNorm1d, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOCsFkxT8yAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = Generator(CH_SIZE, LATENT_SIZE, HIDDEN_SIZE, device=device)\n",
        "if load_gen:\n",
        "    gen.load_state_dict(torch.load(OUT+'{}_{}px_{}epoch.pkl'.format(gen_name, *load_gen)))\n",
        "    gen.eval()\n",
        "else:\n",
        "    gen.apply(weights_init)\n",
        "\n",
        "dis = Discriminator(out_ch=1, device=device)\n",
        "if load_dis:\n",
        "    dis.load_state_dict(torch.load(OUT+'{}_{}px_{}epoch.pkl'.format(dis_name, *load_dis)))\n",
        "    dis.eval()\n",
        "else:\n",
        "    dis.apply(weights_init)\n",
        "\n",
        "gen.to(device)\n",
        "dis.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh2tOT6nbjxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_gen = optim.Adam(\n",
        "    gen.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=(0.5, 0.999),\n",
        "    weight_decay=gen_weight_decay\n",
        "    )\n",
        "opt_dis = optim.Adam(\n",
        "    dis.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=(0.5, 0.999),\n",
        "    weight_decay=dis_weight_decay\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWIg15KG17lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_losses = list()\n",
        "dis_losses = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBbx84zdKHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tweet_interval:\n",
        "    auth = tweepy.OAuthHandler(twitter_api_key.CONSUMER_KEY, twitter_api_key.CONSUMER_SECRET)\n",
        "    auth.set_access_token(twitter_api_key.ACCESS_TOKEN_KEY, twitter_api_key.ACCESS_TOKEN_SECRET)\n",
        "    api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvPMnP12KDyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_log(i, epoch, g_loss, d_loss, g_mean, d_real_mean, d_fake_mean):\n",
        "    print('[{}/{}]\\tLoss_D: {:.4f}\\tLoss_G: {:.4f}\\tD(x): {:.4f}\\tD(G(z)): {:.4f}/{:.4f}'.format(\n",
        "        i, epoch, d_loss, g_loss, d_real_mean, d_fake_mean, g_mean\n",
        "    ))\n",
        "    gen_losses.append(g_loss)\n",
        "    dis_losses.append(d_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLOB11ezFNMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_image(gen, img_size, delta=None):\n",
        "    clear_output()\n",
        "    with torch.no_grad():\n",
        "        generated = gen(8, img_size, delta).detach().cpu()\n",
        "    generated = np.transpose(np.reshape(generated, (-1, 3, img_size, img_size)), (0, 2, 3, 1))\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "        \n",
        "    for i, img in enumerate(generated):\n",
        "        plt.subplot(2, 4, i+1).axis('off')\n",
        "        plt.subplot(2, 4, i+1).imshow(Image.fromarray(np.uint8((img+1.)/2. *255.)))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZoVZoMey7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_upload(image_array, api):\n",
        "    bin_io = io.BytesIO()\n",
        "    img = Image.fromarray(np.uint8((image_array+1.)/2. *255.))\n",
        "    img = img.resize((512, 512), resample=0)\n",
        "    img.save(bin_io, format='JPEG')\n",
        "    result = api.media_upload(filename='{}_generated_{}.jpg'.format(target, uuid.uuid4()), file=bin_io)\n",
        "    return result.media_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myBTJoApd-lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def post_image(gen, api, img_size, iteration, epoch, delta=None):\n",
        "    with torch.no_grad():\n",
        "        generated = gen(16, img_size, delta).detach().cpu()\n",
        "    generated = np.reshape(generated, (4, 2, 2, 3, img_size, img_size))\n",
        "    generated = np.transpose(generated, (0, 3, 1, 4, 2, 5))\n",
        "    generated = np.reshape(generated, (4, 3, img_size*2, img_size*2))\n",
        "    generated = np.transpose(generated, (0, 2, 3, 1))\n",
        "\n",
        "    try:\n",
        "        img_ids = [image_upload(img, api) for img in generated]\n",
        "        hash_tags = ['AIで{}を作る'.format(target_JP),\n",
        "                    'iteration/epoch: {}/{}'.format(iteration+1, epoch+1),\n",
        "                    '#makeing{}'.format(target),\n",
        "                    '#nowlearning...',\n",
        "                    '#AI',\n",
        "                    '#人工知能',\n",
        "                    '#DeepLearning',\n",
        "                    '#GAN']\n",
        "\n",
        "        api.update_status(\n",
        "            status='\\n'.join(hash_tags),\n",
        "            media_ids=img_ids\n",
        "            )\n",
        "    except Exception:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u84LrAZ6Fm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(gen, dis, img_size, epoch):\n",
        "    torch.save(gen.state_dict(), OUT+'{}_{}px_{}epoch.pkl'.format(gen_name, img_size, epoch))\n",
        "    torch.save(dis.state_dict(), OUT+'{}_{}px_{}epoch.pkl'.format(dis_name, img_size, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyoRMEDz8DUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_result():\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(gen_losses,label=\"G\")\n",
        "    plt.plot(dis_losses,label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2qg08QSICrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def round_dataset(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, delta, device):\n",
        "    loss_fun = nn.MSELoss()\n",
        "    data_len = len(dataloader)\n",
        "    for i, data in tqdm(enumerate(dataloader, 0)):\n",
        "        _delta = None\n",
        "        dis.zero_grad()\n",
        "        x_real = data[0].to(device)\n",
        "        b_size = x_real.size(0)\n",
        "        y_real = dis(x_real, img_size, _delta).view(-1)\n",
        "        real_loss = loss_fun(y_real, torch.ones(*y_real.size(), device=device))\n",
        "        real_loss.backward()\n",
        "\n",
        "        x_fake = gen(b_size, img_size, _delta)\n",
        "        y_fake = dis(x_fake.detach(), img_size, _delta).view(-1)\n",
        "        fake_loss = loss_fun(y_fake, torch.zeros(*y_fake.size(), device=device))\n",
        "        fake_loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            clip_grad_norm_(dis.parameters(), grad_clip)\n",
        "        dis_loss = real_loss + fake_loss\n",
        "        opt_dis.step()\n",
        "        \n",
        "        gen.zero_grad()\n",
        "        y_gen = dis(x_fake, img_size, _delta).view(-1)\n",
        "        gen_loss = loss_fun(y_gen, torch.ones(*y_gen.size(), device=device))\n",
        "        gen_loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            clip_grad_norm_(gen.parameters(), grad_clip)\n",
        "        opt_gen.step()\n",
        "\n",
        "        if display_interval and (i+1) % display_interval == 0:\n",
        "            make_image(gen, img_size, _delta)\n",
        "\n",
        "        if (i+1) % log_interval == 0:\n",
        "            report_log(\n",
        "                i,\n",
        "                data_len,\n",
        "                gen_loss.item(),\n",
        "                dis_loss.item(),\n",
        "                y_gen.mean().item(),\n",
        "                y_real.mean().item(),\n",
        "                y_fake.mean().item()\n",
        "                )\n",
        "\n",
        "        if tweet_interval and (i+1) % tweet_interval == 0:\n",
        "            post_image(gen, api, img_size, i, epoch, _delta)\n",
        "        \n",
        "        if snapshot_interval and (i+1) % snapshot_interval == 0:\n",
        "            save_model(gen, dis, img_size, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR5sYeZJI9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, device):\n",
        "    for i in range(epoch):\n",
        "        delta = None\n",
        "        \n",
        "        gen.train()\n",
        "        dis.train()\n",
        "        round_dataset(gen, dis, opt_gen, opt_dis, dataloader, i, img_size, delta, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5K3OZn2JhGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upscaling(gen, dis, opt_gen, opt_dis, device):\n",
        "    img_size = 4*2**START\n",
        "    for epoch, batch_size in zip(EPOCHS[START:], BATCH_SIZES[START:]):\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                                                 transforms.Resize(img_size),\n",
        "                                                                 transforms.RandomCrop(img_size),\n",
        "                                                                 transforms.RandomHorizontalFlip(),\n",
        "                                                                 transforms.ToTensor(),\n",
        "                                                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                                                 ]))\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        train_loop(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, device)\n",
        "        img_size = img_size*2\n",
        "    report_result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefwIhPNI4hL",
        "colab_type": "code",
        "outputId": "2a06f751-c8d6-415a-f8c6-19e21e854a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0f4740d92ebe4a6b82a0cd1cbc9a0529",
            "3efcd9860f654546b8d55dbce4f6702d",
            "734cffdc06af48df9ea2328f914e85c9",
            "2537dac877d24de08f17806d23a42057",
            "07e07267b9af4deebeaba2007ceb187c",
            "0f66f668e88048d496a5a47e40e776b9",
            "dc2450beb9704d98b4ffcfec325036d9",
            "1273d173a3e94473b619cbdc54f70cef"
          ]
        }
      },
      "source": [
        "upscaling(gen, dis, opt_gen, opt_dis, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f4740d92ebe4a6b82a0cd1cbc9a0529"
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqzasKfBlk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_image(gen, 256)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}