{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of make_LANDSCAPE_pretrain_Generator_v0.3.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2LONgCSHkKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target\n",
        "target = 'landscape'\n",
        "target_JP = '風景'\n",
        "\n",
        "# hyper params\n",
        "EPOCHS = (24, 32, 48, 64, 64, 64, 64)\n",
        "BATCH_SIZES = (768, 512, 384, 256, 192, 128, 96)\n",
        "initial_scale = 1.\n",
        "GPU = 0\n",
        "\n",
        "# extension params\n",
        "log_interval = 500\n",
        "display_interval = None\n",
        "tweet_interval = 1000\n",
        "snapshot_interval = 1000\n",
        "\n",
        "# model params\n",
        "sa_gamma = 1.\n",
        "SCALEUP_ALPHA = 1\n",
        "START = 0\n",
        "IMG_SIZE = 256\n",
        "LATENT_SIZE = 512\n",
        "CH_SIZE = 64\n",
        "\n",
        "# learning controller\n",
        "learning_rate = 2e-4\n",
        "grad_clip = None\n",
        "gen_weight_decay = 0\n",
        "dis_weight_decay = 0\n",
        "sa_endpoint = 1000\n",
        "sg_endpoint = 1\n",
        "\n",
        "# file names\n",
        "load_gen = None\n",
        "load_dis = None\n",
        "\n",
        "OUT = './result/'\n",
        "dataroot = './picture/train_pic/flickr/landscape'\n",
        "\n",
        "gen_name = '{}_gen'.format(target)\n",
        "dis_name = '{}_dis'.format(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "taibgWsxewAT",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import io\n",
        "import uuid\n",
        "import pickle\n",
        "import tweepy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm, clip_grad_norm_\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import twitter_api_key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sMBmUGbfmmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian(size):\n",
        "    return torch.normal(torch.zeros(size), torch.ones(size))\n",
        "\n",
        "def pixel_noise(x, k):\n",
        "    return torch.normal(x, torch.abs(x)*k)\n",
        "\n",
        "def zeropad(x, ch):\n",
        "    return F.pad(x, (0, 0, 0, 0, 0, ch-x.size(1), 0, 0))\n",
        "\n",
        "def gap(x):\n",
        "    return F.avg_pool2d(x, x.size()[-2:])\n",
        "\n",
        "def noise_injection(x, k):\n",
        "    return torch.normal(x, instance_var(x)*k)\n",
        "\n",
        "def instance_var(x):\n",
        "    _shape = x.size()\n",
        "    _x = x.view(_shape[0], _shape[1], -1)\n",
        "    _x = torch.var(_x, dim=2)\n",
        "    _x = _x.view(*_x.size(), 1, 1)\n",
        "    _x = _x.expand(*_shape)\n",
        "    return _x\n",
        "\n",
        "def pixel_norm(x):\n",
        "    return x * torch.rsqrt((x**2).mean(1, keepdim=True) + 1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "255V-NaDeLIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=1, stride=1, padding=0):\n",
        "        super(SNConv, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Conv2d(in_ch, out_ch, kernel, stride, padding))\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWziEjG0ZooZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNRes(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=3, stride=1, padding=1):\n",
        "        super(SNRes, self).__init__()\n",
        "        self.main = SNConv(in_ch, out_ch, kernel, stride, padding)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x + self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdvHzeEdlxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNDense(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(SNDense, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            spectral_norm(nn.Linear(in_ch, out_ch))\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz5PrYJQex1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNSelfAttentionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, gamma=1.):\n",
        "        super(SNSelfAttentionBlock, self).__init__()\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.cf = SNConv(in_ch, out_ch//8)\n",
        "        self.cg = SNConv(in_ch, out_ch//8)\n",
        "        self.ch = SNConv(in_ch, out_ch)\n",
        "        self.softmax = nn.Softmax(2)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        f = self.cf(x)\n",
        "        g = self.cg(x)\n",
        "        h = self.ch(x)\n",
        "        f = f.view(f.size(0), f.size(1), -1)\n",
        "        g = g.view(g.size(0), g.size(1), -1)\n",
        "        h = h.view(h.size(0), h.size(1), -1)\n",
        "        \n",
        "        attention_map = torch.bmm(torch.transpose(f, 1, 2), g)\n",
        "        attention_map = self.softmax(attention_map)\n",
        "        feature_map = torch.bmm(h, torch.transpose(attention_map, 1, 2))\n",
        "        feature_map = feature_map.view(*x.size())\n",
        "\n",
        "        return x + feature_map*self.gamma\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        self.gamma = gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yv0ZlRisUb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MinibatchDiscrimination(nn.Module):\n",
        "    def __init__(self, in_ch, kernel, kernel_dims, device):\n",
        "        super(MinibatchDiscrimination, self).__init__()\n",
        "        self.device = device\n",
        "        self.kernel = kernel\n",
        "        self.dim = kernel_dims\n",
        "        self.t = nn.Linear(in_ch, self.kernel*self.dim, bias=False)\n",
        "        for param in self.t.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batchsize = x.size(0)\n",
        "        m = self.t(x).view(batchsize, self.kernel, self.dim, 1)\n",
        "        m_T = torch.transpose(m, 0, 3)\n",
        "        m, m_T = torch.broadcast_tensors(m, m_T)\n",
        "        norm = torch.sum(F.l1_loss(m, m_T, reduction='none'), dim=2)\n",
        "\n",
        "        eraser = torch.eye(batchsize, device=self.device).view(batchsize, 1, batchsize).expand(norm.size())\n",
        "        c_b = torch.exp(-(norm + 1e6 * eraser))\n",
        "        o_b = torch.sum(c_b, dim=2)\n",
        "        h = torch.cat((x, o_b), dim=1)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By7GhkDdFG_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "\n",
        "        self.layer_11 = SNConv(in_ch, mid_ch)\n",
        "        self.layer_33_1 = nn.Sequential(\n",
        "            SNConv(in_ch, mid_ch),\n",
        "            SNConv(mid_ch, mid_ch, 3, 1, 1)\n",
        "        )\n",
        "        self.layer_33_2 = nn.Sequential(\n",
        "            SNConv(in_ch, mid_ch),\n",
        "            SNConv(mid_ch, mid_ch, 3, 1, 1),\n",
        "            SNRes(mid_ch, mid_ch)\n",
        "        )\n",
        "\n",
        "        self.c = SNConv(mid_ch*3, out_ch)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        h_11 = self.layer_11(x)\n",
        "        h_33_1 = self.layer_33_1(x)\n",
        "        h_33_2 = self.layer_33_2(x)\n",
        "        \n",
        "        h = torch.cat((h_11, h_33_1, h_33_2), dim=1)\n",
        "        h = self.c(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAucx40aUr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(InceptionResBlock, self).__init__()\n",
        "        self.ch = out_ch\n",
        "        self.inception = InceptionBlock(in_ch, self.ch//4, self.ch)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        _h = self.inception(x)\n",
        "        h = zeropad(x, self.ch)\n",
        "        return h + _h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-drx6j6OvQpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, sa_gamma=None):\n",
        "        super(DiscriminatorBlock, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            InceptionResBlock(in_ch, in_ch*3//2),\n",
        "            InceptionResBlock(in_ch*3//2, in_ch*2)\n",
        "        )\n",
        "        self.sa = SNSelfAttentionBlock(in_ch*2, in_ch*2, gamma=sa_gamma) if sa_gamma else None\n",
        "\n",
        "        self.c = SNConv(in_ch*2, out_ch)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        h = self.main(x)\n",
        "\n",
        "        if self.sa:\n",
        "            h = self.sa(h)\n",
        "\n",
        "        h = self.c(h)\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        if self.sa:\n",
        "            self.sa.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzW6AWqpGp8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, out_ch=2, alpha=0.5, device=None, sa_gamma=1.):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.in_256 = spectral_norm(nn.Conv2d(3, 32, 1, 1, 0))\n",
        "        self.layer_256 = nn.Sequential(\n",
        "            DiscriminatorBlock(32, 64),\n",
        "            SNConv(64, 64, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_128 = spectral_norm(nn.Conv2d(3, 64, 1, 1, 0))\n",
        "        self.layer_128 = nn.Sequential(\n",
        "            DiscriminatorBlock(64, 128),\n",
        "            SNConv(128, 128, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_64 = spectral_norm(nn.Conv2d(3, 128, 1, 1, 0))\n",
        "        self.layer_64 = nn.Sequential(\n",
        "            DiscriminatorBlock(128, 256),\n",
        "            SNConv(256, 256, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_32 = spectral_norm(nn.Conv2d(3, 256, 1, 1, 0))\n",
        "        self.layer_32 = nn.Sequential(\n",
        "            DiscriminatorBlock(256, 512),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_16 = spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_16 = nn.Sequential(\n",
        "            DiscriminatorBlock(512, 512, sa_gamma=sa_gamma),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_8 = spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_8 = nn.Sequential(\n",
        "            DiscriminatorBlock(512, 512, sa_gamma=sa_gamma),\n",
        "            SNConv(512, 512, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.in_4 =  spectral_norm(nn.Conv2d(3, 512, 1, 1, 0))\n",
        "        self.layer_4 = nn.Sequential(\n",
        "            DiscriminatorBlock(512, 512, sa_gamma=sa_gamma),\n",
        "            nn.AvgPool2d(4),\n",
        "            nn.Flatten(),\n",
        "            MinibatchDiscrimination(512, 64, 16, device),\n",
        "            SNDense(512+64, out_ch)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, img_size, delta=None):\n",
        "\n",
        "        if img_size >= 256:\n",
        "            h = self.in_256(x)\n",
        "            h = self.layer_256(h)\n",
        "        else:\n",
        "            h = 0\n",
        "        \n",
        "        if img_size >= 128:\n",
        "            if img_size == 128:\n",
        "                _x = F.avg_pool2d(x, img_size//128)\n",
        "                h = h + self.in_128(_x)\n",
        "            elif delta and img_size == 256:\n",
        "                _x = F.avg_pool2d(x, img_size//128)\n",
        "                h = torch.lerp(self.in_128(_x), h, delta)\n",
        "            h = self.layer_128(h)\n",
        "        \n",
        "        if img_size >= 64:\n",
        "            if img_size == 64:\n",
        "                _x = F.avg_pool2d(x, img_size//64)\n",
        "                h = h + self.in_64(_x)\n",
        "            elif delta and img_size == 128:\n",
        "                _x = F.avg_pool2d(x, img_size//64)\n",
        "                h = torch.lerp(self.in_64(_x), h, delta)\n",
        "            h = self.layer_64(h)\n",
        "        \n",
        "        if img_size >= 32:\n",
        "            if img_size == 32:\n",
        "                _x = F.avg_pool2d(x, img_size//32)\n",
        "                h = h + self.in_32(_x)\n",
        "            elif delta and img_size == 64:\n",
        "                _x = F.avg_pool2d(x, img_size//32)\n",
        "                h = torch.lerp(self.in_32(_x), h, delta)\n",
        "            h = self.layer_32(h)\n",
        "        \n",
        "        if img_size >= 16:\n",
        "            if img_size == 16:\n",
        "                _x = F.avg_pool2d(x, img_size//16)\n",
        "                h = h + self.in_16(_x)\n",
        "            elif delta and img_size == 32:\n",
        "                _x = F.avg_pool2d(x, img_size//16)\n",
        "                h = torch.lerp(self.in_16(_x), h, delta)\n",
        "            h = self.layer_16(h)\n",
        "\n",
        "        if img_size >= 8:\n",
        "            if img_size == 8:\n",
        "                _x = F.avg_pool2d(x, img_size//8)\n",
        "                h = h + self.in_8(_x)\n",
        "            elif delta and img_size == 16:\n",
        "                _x = F.avg_pool2d(x, img_size//8)\n",
        "                h = torch.lerp(self.in_8(_x), h, delta)\n",
        "            h = self.layer_8(h)\n",
        "\n",
        "        if img_size == 4:\n",
        "            _x = F.avg_pool2d(x, img_size//4)\n",
        "            h = h + self.in_4(_x)\n",
        "        elif delta and img_size == 8:\n",
        "            _x = F.avg_pool2d(x, img_size//4)\n",
        "            h = torch.lerp(self.in_4(_x), h, delta)\n",
        "        h = self.layer_4(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def set_gamma(self, gamma, img_size):\n",
        "        if img_size == 8:\n",
        "            self.layer_4[0].set_gamma(gamma)\n",
        "        if img_size == 16:\n",
        "            self.layer_8[0].set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_eAdhoWCUkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BNConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=1, stride=1, padding=0):\n",
        "        super(BNConv, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_ch, out_ch, kernel, stride, padding),\n",
        "            nn.BatchNorm2d(out_ch)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSUb1GnRygOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BNDense(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(BNDense, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(in_ch, out_ch),\n",
        "            nn.BatchNorm1d(out_ch)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGvG1JXPvr7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Affine(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch=64, w_ch=128):\n",
        "        super(Affine, self).__init__()\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(in_ch, mid_ch),\n",
        "            nn.BatchNorm1d(mid_ch),\n",
        "            BNDense(mid_ch, mid_ch),\n",
        "            BNDense(mid_ch, mid_ch),\n",
        "            BNDense(mid_ch, mid_ch),\n",
        "            BNDense(mid_ch, mid_ch),\n",
        "            BNDense(mid_ch, mid_ch),\n",
        "            BNDense(mid_ch, mid_ch),\n",
        "            BNDense(mid_ch, w_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(pixel_norm(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l6q3ALNCTHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BNSelfAttentionBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, gamma=1.):\n",
        "        super(BNSelfAttentionBlock, self).__init__()\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.cf = BNConv(in_ch, out_ch//8)\n",
        "        self.cg = BNConv(in_ch, out_ch//8)\n",
        "        self.ch = BNConv(in_ch, out_ch)\n",
        "        self.softmax = nn.Softmax(2)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        f = self.cf(x)\n",
        "        g = self.cg(x)\n",
        "        h = self.ch(x)\n",
        "        f = f.view(f.size(0), f.size(1), -1)\n",
        "        g = g.view(g.size(0), g.size(1), -1)\n",
        "        h = h.view(h.size(0), h.size(1), -1)\n",
        "        \n",
        "        attention_map = torch.bmm(torch.transpose(f, 1, 2), g)\n",
        "        attention_map = self.softmax(attention_map)\n",
        "        feature_map = torch.bmm(h, torch.transpose(attention_map, 1, 2))\n",
        "        feature_map = feature_map.view(*x.size())\n",
        "\n",
        "        return x + feature_map*self.gamma\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        self.gamma = gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5QjPrpBKEp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch):\n",
        "        super(SEBlock, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            BNDense(in_ch, mid_ch),\n",
        "            BNDense(mid_ch, in_ch),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.main(x)\n",
        "        return x*h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scShQFu8ttNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoiseInjection(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, device=None):\n",
        "        super(NoiseInjection, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.var = nn.Sequential(\n",
        "            SEBlock(in_ch, in_ch//4),\n",
        "            SNDense(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        var = self.var(w)\n",
        "        var = var.view(*var.size(), 1, 1).expand(*x.size())\n",
        "        noise = gaussian(x.size()).to(self.device)\n",
        "        return x + noise * var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KdRypCUwmjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaIN(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, device=None):\n",
        "        super(AdaIN, self).__init__()\n",
        "\n",
        "        self.noise_injection = NoiseInjection(in_ch, out_ch, device)\n",
        "        self.se = SEBlock(in_ch, in_ch//4)\n",
        "        self.average_convert = SNDense(in_ch, out_ch)\n",
        "        self.bias_convert = SNDense(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        h = F.instance_norm(x)\n",
        "        h = self.noise_injection(h, w)\n",
        "        \n",
        "        _w = self.se(w)\n",
        "        a = self.average_convert(_w)\n",
        "        a = a.view(*a.size(), 1, 1).expand(*h.size())\n",
        "        b = self.bias_convert(_w)\n",
        "        b = b.view(*b.size(), 1, 1).expand(*h.size())\n",
        "        h = h * a + b\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zTVuBAFqAjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DepthwiseCondConv(nn.Module):\n",
        "    def __init__(self, in_ch, n_kernels, kernel=3, stride=1, padding=1, device=None, k=1):\n",
        "        super(DepthwiseCondConv, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.kernel = kernel\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.ch = in_ch\n",
        "        self.kernels_size = (n_kernels, kernel, kernel)\n",
        "\n",
        "        self.weight = nn.Parameter(torch.empty(n_kernels*kernel*kernel, k, 1))\n",
        "        nn.init.xavier_normal_(self.weight)\n",
        "    \n",
        "    def forward(self, x, sigma, bias=None):\n",
        "        b_size = x.size(0)\n",
        "\n",
        "        h = F.leaky_relu(x, negative_slope=0.2)\n",
        "\n",
        "        kernels = self.weight.expand(-1, -1, self.ch)\n",
        "        i = torch.eye(self.ch).to(self.device).view(1, self.ch, self.ch).expand(kernels.size(0), -1, -1)\n",
        "        kernels = i*kernels\n",
        "        kernels = kernels.view(*self.kernels_size, self.ch, -1)\n",
        "        kernels = kernels.transpose(1, 3).transpose(2, 4)\n",
        "        kernels = kernels.expand(b_size, -1, -1, -1, -1, -1)\n",
        "\n",
        "        _s = sigma.view(*kernels.size()[:3], 1, 1, 1)\n",
        "        _s = _s.expand(-1, -1, -1, self.ch, -1, -1)\n",
        "        _s = torch.sum(kernels*_s, dim=1)\n",
        "        _s = _s.reshape(b_size, self.ch, -1)\n",
        "\n",
        "        h = F.unfold(h, self.kernel, padding=self.padding, stride=self.stride)\n",
        "        h = torch.bmm(_s, h)\n",
        "        h = h.view(b_size, self.ch, *x.size()[2:])\n",
        "\n",
        "        if bias is not None:\n",
        "            _b = bias.view(-1, self.ch, 1, 1)\n",
        "            h = h + _b\n",
        "        \n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yiNF-rUsXo9i",
        "colab": {}
      },
      "source": [
        "class SynthBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, latent_w, kernels, device=None):\n",
        "        super(SynthBlock, self).__init__()\n",
        "\n",
        "        self.se = SEBlock(latent_w, latent_w//4)\n",
        "        self.sigma = nn.Sequential(\n",
        "            SNDense(latent_w, in_ch*kernels),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.bias = SNDense(latent_w, in_ch)\n",
        "\n",
        "        self.dcc = spectral_norm(DepthwiseCondConv(in_ch, kernels, device=device))\n",
        "        self.c = SNConv(in_ch, out_ch)\n",
        "        self.adain = AdaIN(latent_w, out_ch, device)\n",
        "            \n",
        "    def forward(self, x, w):\n",
        "        _w = self.se(w)\n",
        "        sigma = self.sigma(_w)\n",
        "        bias = self.bias(_w)\n",
        "\n",
        "        h = self.dcc(x, sigma, bias)\n",
        "        h = self.c(h)\n",
        "        h = self.adain(h, w)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2Rk_jFc7Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, latent_w, kernels, device=None, sa_gamma=None):\n",
        "        super(GeneratorBlock, self).__init__()\n",
        "        self.w_size = latent_w\n",
        "\n",
        "        self.synth_0 = SynthBlock(in_ch, out_ch, latent_w, kernels, device)\n",
        "        self.synth_1 = SynthBlock(out_ch, out_ch, latent_w, kernels, device)\n",
        "        self.synth_2 = SynthBlock(out_ch, out_ch, latent_w, kernels, device)\n",
        "        self.sa = SNSelfAttentionBlock(out_ch, out_ch, gamma=sa_gamma) if sa_gamma else None\n",
        "        \n",
        "        self.c_out = SNConv(out_ch, 3)\n",
        "            \n",
        "    def forward(self, x, w):\n",
        "        _w = w[:, :self.w_size]\n",
        "\n",
        "        h = self.synth_0(x, _w)\n",
        "        h = h + self.synth_1(h, _w)\n",
        "        h = h + self.synth_2(h, _w)\n",
        "        if self.sa:\n",
        "            h = self.sa(h)\n",
        "            \n",
        "        out = self.c_out(h)\n",
        "        return h, out\n",
        "\n",
        "    def set_gamma(self, gamma):\n",
        "        if self.sa:\n",
        "            self.sa.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKEhOWEuFqEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_size, ch_size, alpha=0.5, latent_blur=0.1, device=None, sa_gamma=1., kernels=4):\n",
        "        super(Generator, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.latent_blur = latent_blur\n",
        "        incremental_size = (latent_size-224)//32\n",
        "\n",
        "        self.btm = nn.Parameter(torch.empty(1, ch_size, 4, 4))\n",
        "        nn.init.normal_(self.btm)\n",
        "        \n",
        "        self.affine = Affine(latent_size, latent_size, latent_size)\n",
        "        \n",
        "        self.res6 = GeneratorBlock(ch_size, ch_size, 32, kernels, device, sa_gamma)\n",
        "        self.res5 = GeneratorBlock(ch_size, ch_size, 64+incremental_size, kernels,  device, sa_gamma)\n",
        "        self.res4 = GeneratorBlock(ch_size, ch_size, 96+incremental_size*2, kernels, device)\n",
        "        self.res3 = GeneratorBlock(ch_size, ch_size, 128+incremental_size*4, kernels, device)\n",
        "        self.res2 = GeneratorBlock(ch_size, ch_size, 160+incremental_size*8, kernels, device)\n",
        "        self.res1 = GeneratorBlock(ch_size, ch_size, 192+incremental_size*16, kernels, device)\n",
        "        self.res0 = GeneratorBlock(ch_size, ch_size, latent_size, kernels, device)\n",
        "\n",
        "        self.upbi = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "    \n",
        "    def forward(self, x, img_size, delta=None, mixing=False):\n",
        "        w = self.affine(x)\n",
        "        h = self.btm.expand(x.size(0), -1, -1, -1)\n",
        "        h, out = self.res6(h, w)\n",
        "        \n",
        "        if img_size >= 8:\n",
        "            h = self.upbi(h)\n",
        "            _x = pixel_noise(x, self.latent_blur)\n",
        "            w = self.affine(_x) if mixing else w\n",
        "            h, _out = self.res5(h, w)\n",
        "            if delta and img_size == 8:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "        \n",
        "        if img_size >= 16:\n",
        "            h = self.upbi(h)\n",
        "            _x = pixel_noise(x, self.latent_blur)\n",
        "            w = self.affine(_x) if mixing else w\n",
        "            h, _out = self.res4(h, w)\n",
        "            if delta and img_size == 16:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "\n",
        "        if img_size >= 32:\n",
        "            h = self.upbi(h)\n",
        "            _x = pixel_noise(x, self.latent_blur)\n",
        "            w = self.affine(_x) if mixing else w\n",
        "            h, _out = self.res3(h, w)\n",
        "            if delta and img_size == 32:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "\n",
        "        if img_size >= 64:\n",
        "            h = self.upbi(h)\n",
        "            _x = pixel_noise(x, self.latent_blur)\n",
        "            w = self.affine(_x) if mixing else w\n",
        "            h, _out = self.res2(h, w)\n",
        "            if delta and img_size == 64:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "        \n",
        "        if img_size >= 128:\n",
        "            h = self.upbi(h)\n",
        "            _x = pixel_noise(x, self.latent_blur)\n",
        "            w = self.affine(_x) if mixing else w\n",
        "            h, _out = self.res1(h, w)\n",
        "            if delta and img_size == 128:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "        \n",
        "        if img_size >= 256:\n",
        "            h = self.upbi(h)\n",
        "            _x = pixel_noise(x, self.latent_blur)\n",
        "            w = self.affine(_x) if mixing else w\n",
        "            h, _out = self.res0(h, w)\n",
        "            if delta and img_size == 256:\n",
        "                out = torch.lerp(self.upbi(out), _out, delta)\n",
        "            else:\n",
        "                out = _out\n",
        "\n",
        "        return torch.tanh(out)\n",
        "\n",
        "    def set_gamma(self, gamma, img_size):\n",
        "        if img_size == 8:\n",
        "            self.res6.set_gamma(gamma)\n",
        "        if img_size == 16:\n",
        "            self.res5.set_gamma(gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RvlFlUWVgCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:{}\".format(GPU))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjzxAjvT6VPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    if type(m) in (nn.Linear, nn.Conv2d):\n",
        "        nn.init.xavier_normal_(m.weight, gain=initial_scale)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "    elif type(m) in (nn.BatchNorm1d, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOCsFkxT8yAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = Generator(LATENT_SIZE, CH_SIZE, alpha=SCALEUP_ALPHA, device=device)\n",
        "if load_gen:\n",
        "    gen.load_state_dict(torch.load(OUT+'{}_{}px_{}epoch.pkl'.format(gen_name, *load_weight)))\n",
        "    gen.eval()\n",
        "else:\n",
        "    gen.apply(weights_init)\n",
        "\n",
        "dis = Discriminator(out_ch=1, alpha=SCALEUP_ALPHA, device=device)\n",
        "if load_dis:\n",
        "    dis.load_state_dict(torch.load(OUT+'{}_{}px_{}epoch.pkl'.format(dis_name, *load_weight)))\n",
        "    dis.eval()\n",
        "else:\n",
        "    dis.apply(weights_init)\n",
        "\n",
        "gen.to(device)\n",
        "dis.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh2tOT6nbjxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_gen = optim.Adam(\n",
        "    gen.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=(0.5, 0.999),\n",
        "    weight_decay=gen_weight_decay\n",
        "    )\n",
        "opt_dis = optim.Adam(\n",
        "    dis.parameters(),\n",
        "    lr=learning_rate,\n",
        "    betas=(0.5, 0.999),\n",
        "    weight_decay=dis_weight_decay\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWIg15KG17lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_losses = list()\n",
        "dis_losses = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBbx84zdKHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tweet_interval:\n",
        "    auth = tweepy.OAuthHandler(twitter_api_key.CONSUMER_KEY, twitter_api_key.CONSUMER_SECRET)\n",
        "    auth.set_access_token(twitter_api_key.ACCESS_TOKEN_KEY, twitter_api_key.ACCESS_TOKEN_SECRET)\n",
        "    api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvPMnP12KDyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_log(i, epoch, g_loss, d_loss, g_mean, d_real_mean, d_fake_mean):\n",
        "    print('[{}/{}]\\tLoss_D: {:.4f}\\tLoss_G: {:.4f}\\tD(x): {:.4f}\\tD(G(z)): {:.4f}/{:.4f}'.format(\n",
        "        i, epoch, d_loss, g_loss, d_real_mean, d_fake_mean, g_mean\n",
        "    ))\n",
        "    gen_losses.append(g_loss)\n",
        "    dis_losses.append(d_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLOB11ezFNMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_image(gen, img_size, device, delta=None, mixing=False):\n",
        "    clear_output()\n",
        "    with torch.no_grad():\n",
        "        generated = gen(gaussian((8, LATENT_SIZE)).to(device), img_size, delta, mixing).detach().cpu()\n",
        "    generated = np.transpose(np.reshape(generated, (-1, 3, img_size, img_size)), (0, 2, 3, 1))\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "        \n",
        "    for i, img in enumerate(generated):\n",
        "        plt.subplot(2, 4, i+1).axis('off')\n",
        "        plt.subplot(2, 4, i+1).imshow(Image.fromarray(np.uint8((img+1.)/2. *255.)))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZoVZoMey7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_upload(image_array, api):\n",
        "    bin_io = io.BytesIO()\n",
        "    img = Image.fromarray(np.uint8((image_array+1.)/2. *255.))\n",
        "    img = img.resize((512, 512), resample=0)\n",
        "    img.save(bin_io, format='JPEG')\n",
        "    result = api.media_upload(filename='{}_generated_{}.jpg'.format(target, uuid.uuid4()), file=bin_io)\n",
        "    return result.media_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myBTJoApd-lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def post_image(gen, api, img_size, iteration, epoch, device, delta=None, mixing=False):\n",
        "    with torch.no_grad():\n",
        "        generated = gen(gaussian((16, LATENT_SIZE)).to(device), img_size, delta, mixing).detach().cpu()\n",
        "    generated = np.reshape(generated, (4, 2, 2, 3, img_size, img_size))\n",
        "    generated = np.transpose(generated, (0, 3, 1, 4, 2, 5))\n",
        "    generated = np.reshape(generated, (4, 3, img_size*2, img_size*2))\n",
        "    generated = np.transpose(generated, (0, 2, 3, 1))\n",
        "\n",
        "    try:\n",
        "        img_ids = [image_upload(img, api) for img in generated]\n",
        "        hash_tags = ['AIで{}を作る'.format(target_JP),\n",
        "                    'iteration/epoch: {}/{}'.format(iteration+1, epoch+1),\n",
        "                    '#makeing{}'.format(target),\n",
        "                    '#nowlearning...',\n",
        "                    '#AI',\n",
        "                    '#人工知能',\n",
        "                    '#DeepLearning',\n",
        "                    '#GAN']\n",
        "\n",
        "        api.update_status(\n",
        "            status='\\n'.join(hash_tags),\n",
        "            media_ids=img_ids\n",
        "            )\n",
        "    except Exception:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u84LrAZ6Fm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(gen, dis, img_size, epoch):\n",
        "    torch.save(gen.state_dict(), OUT+'{}_{}px_{}epoch.pkl'.format(gen_name, img_size, epoch))\n",
        "    torch.save(dis.state_dict(), OUT+'{}_{}px_{}epoch.pkl'.format(dis_name, img_size, epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyoRMEDz8DUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_result():\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(gen_losses,label=\"G\")\n",
        "    plt.plot(dis_losses,label=\"D\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2qg08QSICrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def round_dataset(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, delta, device, mixing=False):\n",
        "    loss_fun = nn.MSELoss()\n",
        "    data_len = len(dataloader)\n",
        "    for i, data in tqdm(enumerate(dataloader, 0)):\n",
        "        _delta = None\n",
        "        dis.zero_grad()\n",
        "        x_real = data[0].to(device)\n",
        "        b_size = x_real.size(0)\n",
        "        y_real = dis(x_real, img_size, _delta).view(-1)\n",
        "        real_loss = loss_fun(y_real, torch.ones(*y_real.size(), device=device))\n",
        "        real_loss.backward()\n",
        "\n",
        "        x_fake = gen(gaussian((b_size, LATENT_SIZE)).to(device), img_size, _delta, mixing)\n",
        "        y_fake = dis(x_fake.detach(), img_size, _delta).view(-1)\n",
        "        fake_loss = loss_fun(y_fake, torch.zeros(*y_fake.size(), device=device))\n",
        "        fake_loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            clip_grad_norm_(dis.parameters(), grad_clip)\n",
        "        dis_loss = real_loss + fake_loss\n",
        "        opt_dis.step()\n",
        "        \n",
        "        gen.zero_grad()\n",
        "        y_gen = dis(x_fake, img_size, _delta).view(-1)\n",
        "        gen_loss = loss_fun(y_gen, torch.ones(*y_gen.size(), device=device))\n",
        "        gen_loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            clip_grad_norm_(gen.parameters(), grad_clip)\n",
        "        opt_gen.step()\n",
        "\n",
        "        if display_interval and (i+1) % display_interval == 0:\n",
        "            make_image(gen, img_size, device, _delta, mixing)\n",
        "\n",
        "        if (i+1) % log_interval == 0:\n",
        "            report_log(\n",
        "                i,\n",
        "                data_len,\n",
        "                gen_loss.item(),\n",
        "                dis_loss.item(),\n",
        "                y_gen.mean().item(),\n",
        "                y_real.mean().item(),\n",
        "                y_fake.mean().item()\n",
        "                )\n",
        "\n",
        "        if tweet_interval and (i+1) % tweet_interval == 0:\n",
        "            post_image(gen, api, img_size, i, epoch, device, _delta, mixing)\n",
        "        \n",
        "        if snapshot_interval and (i+1) % snapshot_interval == 0:\n",
        "            save_model(gen, dis, img_size, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR5sYeZJI9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, device, mixing=False):\n",
        "    for i in range(epoch):\n",
        "        delta = None\n",
        "        \n",
        "        gen.train()\n",
        "        dis.train()\n",
        "        round_dataset(gen, dis, opt_gen, opt_dis, dataloader, i, img_size, delta, device, mixing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5K3OZn2JhGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upscaling(gen, dis, opt_gen, opt_dis, device, mixing=False):\n",
        "    img_size = 4*2**START\n",
        "    for epoch, batch_size in zip(EPOCHS[START:], BATCH_SIZES[START:]):\n",
        "        dataset = dset.ImageFolder(root=dataroot,\n",
        "                                   transform=transforms.Compose([\n",
        "                                                                 transforms.Resize(img_size),\n",
        "                                                                 transforms.RandomCrop(img_size),\n",
        "                                                                 transforms.RandomHorizontalFlip(),\n",
        "                                                                 transforms.ToTensor(),\n",
        "                                                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                                                 ]))\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        train_loop(gen, dis, opt_gen, opt_dis, dataloader, epoch, img_size, device, mixing)\n",
        "        img_size = img_size*2\n",
        "    report_result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefwIhPNI4hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upscaling(gen, dis, opt_gen, opt_dis, device, mixing=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqzasKfBlk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_image(gen, 256, device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}